{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle as pkl\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from ipywidgets import (\n",
    "    interact,\n",
    "    IntSlider,\n",
    "    RadioButtons\n",
    ")\n",
    "\n",
    "from genome_helpers import (\n",
    "    get_genome_metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_bases(row):\n",
    "    \n",
    "    base_calls = row[\"bases\"]\n",
    "    quality_scores = phred_quality(row[\"qual\"])\n",
    "    ref_base = row[\"ref\"].upper()\n",
    "\n",
    "    base_calls = base_calls.replace(\"$\", \"\").replace(\"^]\", \"\").replace(\"^I\", \"\")\n",
    "    \n",
    "    processed_bases = []\n",
    "    passing_quality_scores = []\n",
    "    \n",
    "    i = 0\n",
    "    while i < row[\"depth\"]:\n",
    "        char = base_calls[i]\n",
    "\n",
    "        # Filtrar por calidad (descartar bases con calidad < 20)\n",
    "        if quality_scores[i] < 20:\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        passing_quality_scores.append(quality_scores[i])\n",
    "        \n",
    "        # Reemplazar referencia\n",
    "        if char in \".,\":  \n",
    "            processed_bases.append(ref_base)\n",
    "\n",
    "        # Contar bases normales\n",
    "        elif char.upper() in \"ACTG\":\n",
    "            processed_bases.append(char.upper())\n",
    "\n",
    "        # Contar deleciones en la referencia (`*`)\n",
    "        elif char == \"*\":\n",
    "            processed_bases.append(\"D\")\n",
    "\n",
    "        # Detectar inserciones (`+nX`)\n",
    "        elif char == \"+\":\n",
    "            match = re.match(r\"\\+(\\d+)\", base_calls[i:])\n",
    "            if match:\n",
    "                num_bases = int(match.group(1))\n",
    "                inserted_seq = base_calls[i+len(match.group(1))+1:i+len(match.group(1))+1+num_bases]\n",
    "                # processed_bases.append(f\"INS_{inserted_seq.upper()}\")\n",
    "                processed_bases.append(\"I\")\n",
    "                i += len(match.group(1)) + num_bases\n",
    "\n",
    "        # Detectar deleciones (`-nX`)\n",
    "        elif char == \"-\":\n",
    "            match = re.match(r\"\\-(\\d+)\", base_calls[i:])\n",
    "            if match:\n",
    "                num_bases = int(match.group(1))\n",
    "                deleted_seq = base_calls[i+len(match.group(1))+1:i+len(match.group(1))+1+num_bases]\n",
    "                processed_bases.append(\"D\")\n",
    "                # processed_bases.append(f\"DEL_{deleted_seq.upper()}\")\n",
    "                i += len(match.group(1)) + num_bases\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    if len(passing_quality_scores) == 0:\n",
    "         allele_counts = { 'A': 0, 'C': 0, 'T': 0, 'G': 0, 'DEL': 0, 'INS': 0, \"Avg_Qual\": None, \"depth\": 0, \"depth_high_q\": 0 }\n",
    "         return allele_counts\n",
    "\n",
    "    allele_counts = {\n",
    "        'A': processed_bases.count('A'),\n",
    "        'C': processed_bases.count('C'),\n",
    "        'T': processed_bases.count('T'),\n",
    "        'G': processed_bases.count('G'),\n",
    "        'DEL': processed_bases.count('D'),\n",
    "        'INS': processed_bases.count('I')\n",
    "    }\n",
    "\n",
    "    # Contar inserciones y deleciones específicas\n",
    "    for item in processed_bases:\n",
    "        if item.startswith(\"INS_\"):\n",
    "            allele_counts[item] = allele_counts.get(item, 0) + 1\n",
    "        if item.startswith(\"DEL_\"):\n",
    "            allele_counts[item] = allele_counts.get(item, 0) + 1\n",
    "\n",
    "    # Calcular calidad promedio\n",
    "    # allele_counts[\"Avg_Qual\"] = np.mean(quality_scores) if quality_scores else 0\n",
    "    allele_counts[\"Avg_Qual\"] = sum(passing_quality_scores) / len(passing_quality_scores) # if quality_scores else 0\n",
    "    allele_counts[\"depth\"] = row[\"depth\"]\n",
    "    allele_counts[\"depth_high_q\"] = len(passing_quality_scores)\n",
    "    allele_counts[\"bases\"] = processed_bases\n",
    "    allele_counts[\"original_bases\"] = row[\"bases\"]\n",
    "    allele_counts[\"ref_base\"] = ref_base\n",
    "    allele_counts[\"quality_scores\"] = quality_scores\n",
    "    \n",
    "    return allele_counts\n",
    "\n",
    "\n",
    "def mismatch(row):\n",
    "    alleles = [ row[x] for x in ['A', 'C', 'T', 'G', 'DEL', 'INS'] ] #, row.C, row.T, row.G]#, row.DEL, row.INS]\n",
    "    # print(sum(alleles) != row.depth_high_q)\n",
    "    return sum(alleles) != row.depth_high_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phred_quality(qual_string):\n",
    "    return [ord(q) - 33 for q in qual_string]\n",
    "\n",
    "\n",
    "def count_alleles(row):\n",
    "\n",
    "    base_calls = row[\"bases\"]    \n",
    "    print(f\"{len(base_calls)=}\")\n",
    "\n",
    "    quality_scores = phred_quality(row[\"qual\"])\n",
    "    print(f\"{quality_scores=}\")\n",
    "    print(f\"{len(quality_scores)=}\")\n",
    "    \n",
    "    ref_base = row[\"ref\"].upper()\n",
    "    print(f\"{ref_base=}\")\n",
    "\n",
    "    base_calls = re.sub(pattern=\"\\^.\", repl=\"\", string=base_calls)\n",
    "    \n",
    "    # base_calls.replace('$', \"\").replace('^]', \"\").replace('^I', \"\")\n",
    "\n",
    "    n_bases = len(base_calls.replace(\"-\", \"\").replace(\"+\", \"\"))\n",
    "\n",
    "    # Reemplazar '.' y ',' con la base de referencia\n",
    "    base_calls = base_calls.replace('.', ref_base).replace(',', ref_base)\n",
    "    print(f\"{base_calls=}\")\n",
    "    print(f\"{len(base_calls)=}\")\n",
    "    \n",
    "    filtered_bases = \"\".join([base_calls[i] for i in range(n_bases) if quality_scores[i] >= 20])\n",
    "    print(filtered_bases)\n",
    "    filtered_quality_scores = sum([quality_scores[i] for i in range(n_bases) if quality_scores[i] >= 20]) /n_bases\n",
    "    \n",
    "    counts = {\n",
    "        'A': filtered_bases.count('A'),\n",
    "        'C': filtered_bases.count('C'),\n",
    "        'T': filtered_bases.count('T'),\n",
    "        'G': filtered_bases.count('G'),\n",
    "        'DEL': filtered_bases.count('*')  # Conteo de deleciones\n",
    "    }\n",
    "\n",
    "    # Buscar inserciones y deleciones en la secuencia de bases\n",
    "    insertions = re.findall(r'\\+(\\d+)([ACGTNacgtn]+)', filtered_bases)\n",
    "    deletions = re.findall(r'\\-(\\d+)([ACGTNacgtn]+)', filtered_bases)\n",
    "\n",
    "    for size, seq in insertions:\n",
    "        key = f\"INS_{ref_base}{seq.upper()}\"\n",
    "        counts[key] = counts.get(key, 0) + 1\n",
    "\n",
    "    for size, seq in deletions:\n",
    "        key = f\"DEL_{seq.upper()}\"\n",
    "        counts[key] = counts.get(key, 0) + 1\n",
    "\n",
    "    \n",
    "    counts[\"Avg_Qual\"] = filtered_quality_scores # np.mean(quality_scores) if quality_scores else 0\n",
    "    \n",
    "    return counts\n",
    "\n",
    "\n",
    "def parse_bases(base_string, ref_base):\n",
    "\n",
    "    i = 0\n",
    "    bases_list = []\n",
    "    \n",
    "    while i < len(base_string):\n",
    "        \n",
    "        char = base_string[i]\n",
    "\n",
    "        # Reemplazar referencia\n",
    "        if char in \".,\":  \n",
    "            current_base = ref_base\n",
    "            bases_list.append(current_base)\n",
    "\n",
    "        # Contar bases normales\n",
    "        elif char.upper() in \"ACTG\":\n",
    "            current_base = char.upper()\n",
    "            bases_list.append(current_base)\n",
    "\n",
    "        # Contar deleciones en la referencia (`*`)\n",
    "        elif char == \"*\":\n",
    "            bases_list.append(\"DEL\")\n",
    "\n",
    "        # Detectar inserciones (`+nX`) y asociarlas correctamente\n",
    "        elif char == \"+\":\n",
    "            match = re.match(r\"\\+(\\d+)\", base_string[i:])\n",
    "            if match:\n",
    "                num_bases = int(match.group(1))\n",
    "                inserted_seq = base_string[i+len(match.group(1))+1:i+len(match.group(1))+1+num_bases]\n",
    "\n",
    "                # Asociar la inserción a la base previa (última base agregada)\n",
    "                if bases_list:\n",
    "                    bases_list[-1] = f\"{bases_list[-1]}_INS_{inserted_seq.upper()}\"\n",
    "                else:\n",
    "                    bases_list.append(f\"INS_{inserted_seq.upper()}\")  # Caso extremo: inserción sin base previa\n",
    "\n",
    "                i += len(match.group(1)) + num_bases  # Salteamos la inserción en el string\n",
    "\n",
    "        # Detectar deleciones (`-nX`)\n",
    "        elif char == \"-\":\n",
    "            match = re.match(r\"\\-(\\d+)\", base_string[i:])\n",
    "            if match:\n",
    "                num_bases = int(match.group(1))\n",
    "                deleted_seq = base_string[i+len(match.group(1))+1:i+len(match.group(1))+1+num_bases]\n",
    "\n",
    "                # Asociar la deleción a la base previa (última base agregada)\n",
    "                if bases_list:\n",
    "                    bases_list[-1] = f\"{bases_list[-1]}_DEL_{deleted_seq.upper()}\"\n",
    "                else:\n",
    "                    bases_list.append(f\"DEL_{deleted_seq.upper()}\")\n",
    "\n",
    "                i += len(match.group(1)) + num_bases  # Salteamos la deleción en el string\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    return bases_list\n",
    "\n",
    "\n",
    "def process_bases(row):\n",
    "    \n",
    "    base_calls = row[\"bases\"]\n",
    "    quality_scores = phred_quality(row[\"qual\"])\n",
    "    ref_base = row[\"ref\"].upper()\n",
    "\n",
    "    base_calls = base_calls.replace(\"$\", \"\").replace(\"^]\", \"\").replace(\"^I\", \"\")\n",
    "\n",
    "    parsed_bases = parse_bases(base_calls, ref_base)\n",
    "\n",
    "    return [Counter(parsed_bases), quality_scores]\n",
    "\n",
    "\n",
    "def process_folder(folder=\"data/genomes/alignments_paired_end\"):\n",
    "    \n",
    "    for raiz, carpetas, archivos in os.walk(folder):\n",
    "        for archivo in archivos:        \n",
    "    \n",
    "            if not (\"counts\" in archivo and archivo.endswith(\"txt\")):\n",
    "                continue\n",
    "    \n",
    "            ruta_completa = os.path.join(raiz, archivo)\n",
    "            batch = os.path.basename(ruta_completa).split(\"__\")[0]        \n",
    "    \n",
    "            df = pd.read_csv(ruta_completa, sep=\"\\t\", header=None)\n",
    "            df.columns = [\"contig\", \"position\", \"ref\", \"depth\", \"bases\", \"qual\"]\n",
    "            df = pd.concat([df, df.apply(lambda x: process_bases(x)[0], axis=1), df.apply(lambda x: process_bases(x)[1], axis=1)], axis=1)\n",
    "            df.columns = df.columns[:-2].to_list() + [\"count\", \"quality\"]\n",
    "            df = df.drop([\"qual\"], axis=1)\n",
    "            df = df.assign(sample=batch)\n",
    "            \n",
    "            (pp := locals().get(\"pp\") or []).append(df)\n",
    "    \n",
    "    pp = pd.concat(pp)[[\"contig\", \"position\", \"sample\", \"count\"]].pivot(index=[\"contig\", \"position\"], columns=\"sample\", values=\"count\")\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_from_counts(allele_dict):\n",
    "    \n",
    "    assert isinstance(allele_dict, dict) or np.isnan(allele_dict)\n",
    "\n",
    "    if not isinstance(allele_dict, dict) and np.isnan(allele_dict):\n",
    "        return dict(depth=0, A=0, T=0, G=0, C=0)\n",
    "    else:\n",
    "        depth = sum(allele_dict.values())\n",
    "        return dict(\n",
    "            depth=depth, \n",
    "            A=allele_dict.get(\"A\", 0), \n",
    "            T=allele_dict.get(\"T\", 0), \n",
    "            G=allele_dict.get(\"G\", 0), \n",
    "            C=allele_dict.get(\"C\", 0))\n",
    "    \n",
    "\n",
    "def plot_allele_freqs(snp_evolution_df):\n",
    "\n",
    "    plt.figure(figsize=(20, 8))\n",
    "\n",
    "    for allele in [\"A\", \"C\", \"T\", \"G\"]:\n",
    "        plt.plot(snp_evolution_df.index, snp_evolution_df[allele], label=f'Alelo {allele}')\n",
    "\n",
    "    if \"depth\" in snp_evolution_df.columns:\n",
    "        plt.plot(snp_evolution_df.index, snp_evolution_df.depth, label=f'Cobertura')\n",
    "\n",
    "    plt.xlabel('Generaciones')\n",
    "    plt.ylabel('Frecuencia alélica')\n",
    "    plt.title('Distribución de alelos a lo largo de generaciones')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_df = ( (df := process_folder())\n",
    "    .map(freq_from_counts)\n",
    "    .melt(ignore_index=False) )\n",
    "\n",
    "batch_mapping = get_genome_metadata(as_dataframe=False)\n",
    "samples = freq_df['sample'].apply(lambda x: batch_mapping.get(x, (x, -1, -1)))\n",
    "samples_df = pd.DataFrame(samples.to_list(), columns=[\"treatment\", \"replica\", \"generation\"])\n",
    "\n",
    "freq_df = pd.concat([samples_df, freq_df.reset_index()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bec73fbc6054a6486b65e9632e10bf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i'), RadioButtons(description='freq_or_count', options=(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MINIMUM_DEPTH = 50\n",
    "\n",
    "@interact\n",
    "def interactive_allele_evolution_plot(i=IntSlider(min=0, max=100), freq_or_count=RadioButtons(options=[\"cuentas\", \"frecuencia\"])):\n",
    "\n",
    "    SNPs = freq_df.drop_duplicates(subset=[\"contig\", \"position\"])[[\"contig\", \"position\"]]\n",
    "    contig, position = SNPs.contig.iloc[i], SNPs.position.iloc[i]\n",
    "\n",
    "    TREATMENT, REPLICA = \"MS\", 3\n",
    "\n",
    "    snp_evolution = ( freq_df\n",
    "        .query(\"treatment == @TREATMENT and replica == @REPLICA\")\n",
    "        .query(\"contig == @contig and position == @position\")\n",
    "        .sort_values(\"generation\") )\n",
    "    \n",
    "    snp_count_evol = snp_evolution.value.apply(lambda x: [x[\"A\"], x[\"C\"], x[\"T\"], x[\"G\"], x['depth']]).set_axis(snp_evolution.generation)\n",
    "    snp_count_evol = pd.DataFrame(snp_count_evol.apply(lambda x: list(x)).to_list(), columns=[\"A\", \"C\", \"T\", \"G\", \"depth\"])    \n",
    "    snp_count_evol = snp_count_evol.query(\"depth > @MINIMUM_DEPTH\")\n",
    "\n",
    "    snp_freq_evol = ( snp_count_evol\n",
    "        .assign(freqA=snp_count_evol.A/snp_count_evol.depth, freqC=snp_count_evol.C/snp_count_evol.depth, freqT=snp_count_evol['T']/snp_count_evol.depth, freqG=snp_count_evol.G/snp_count_evol.depth)\n",
    "        .drop([\"A\", \"C\", \"T\", \"G\", \"depth\"], axis=1)\n",
    "        .rename({ f\"freq{a}\": a for a in [\"A\", \"C\", \"T\", \"G\"] }, axis=1))\n",
    "    \n",
    "    plot_allele_freqs(snp_freq_evol if freq_or_count == \"frecuencia\" else snp_count_evol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq(count_dict):\n",
    "    \n",
    "    assert 'depth' in count_dict\n",
    "    \n",
    "    count_dict = count_dict.copy() \n",
    "    depth = count_dict.pop('depth')\n",
    "    major_allele_count = max(count_dict.values())\n",
    "    if depth < 20:\n",
    "        return np.nan\n",
    "    \n",
    "    return major_allele_count / depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_302620/106596940.py:15: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  .drop([\"contig\", \"position\"], axis=1) )\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>treatment</th>\n",
       "      <th>K</th>\n",
       "      <th colspan=\"3\" halign=\"left\">MS</th>\n",
       "      <th colspan=\"4\" halign=\"left\">K</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MS</th>\n",
       "      <th>...</th>\n",
       "      <th>K</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MS</th>\n",
       "      <th colspan=\"2\" halign=\"left\">K</th>\n",
       "      <th colspan=\"2\" halign=\"left\">MS</th>\n",
       "      <th colspan=\"3\" halign=\"left\">K</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>replica</th>\n",
       "      <th>1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">3</th>\n",
       "      <th>2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">1</th>\n",
       "      <th>3</th>\n",
       "      <th>2</th>\n",
       "      <th>...</th>\n",
       "      <th>2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">3</th>\n",
       "      <th colspan=\"2\" halign=\"left\">2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">3</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generation</th>\n",
       "      <th>39</th>\n",
       "      <th>67</th>\n",
       "      <th>34</th>\n",
       "      <th>27</th>\n",
       "      <th>43</th>\n",
       "      <th>14</th>\n",
       "      <th>38</th>\n",
       "      <th>63</th>\n",
       "      <th>8</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>57</th>\n",
       "      <th>59</th>\n",
       "      <th>17</th>\n",
       "      <th>27</th>\n",
       "      <th>46</th>\n",
       "      <th>43</th>\n",
       "      <th>50</th>\n",
       "      <th>36</th>\n",
       "      <th>7</th>\n",
       "      <th>77</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variant_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(contig000001, 146)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.533632</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(contig000001, 227)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989474</td>\n",
       "      <td>0.858824</td>\n",
       "      <td>0.985849</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.840426</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.672840</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.937984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(contig000001, 5306)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.651316</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.535088</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.523529</td>\n",
       "      <td>0.837696</td>\n",
       "      <td>0.847222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.854962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(contig000001, 91539)</th>\n",
       "      <td>0.591176</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.550063</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.522642</td>\n",
       "      <td>0.733607</td>\n",
       "      <td>0.503704</td>\n",
       "      <td>0.548209</td>\n",
       "      <td>0.545098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558763</td>\n",
       "      <td>0.684380</td>\n",
       "      <td>0.552486</td>\n",
       "      <td>0.516393</td>\n",
       "      <td>0.590840</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.541237</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.507331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(contig000001, 91557)</th>\n",
       "      <td>0.607955</td>\n",
       "      <td>0.531621</td>\n",
       "      <td>0.517073</td>\n",
       "      <td>0.531100</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>0.543119</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.548052</td>\n",
       "      <td>0.558226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558577</td>\n",
       "      <td>0.670455</td>\n",
       "      <td>0.542328</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.602056</td>\n",
       "      <td>0.511848</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.522843</td>\n",
       "      <td>0.998088</td>\n",
       "      <td>0.512676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(contig000029, 696)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992620</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998752</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998371</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(contig000032, 8535)</th>\n",
       "      <td>0.994152</td>\n",
       "      <td>0.969027</td>\n",
       "      <td>0.176166</td>\n",
       "      <td>0.997727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986755</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.989796</td>\n",
       "      <td>0.998294</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(contig000038, 58)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.644628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(contig000038, 105)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.177419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.456790</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.503205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095745</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(contig000038, 155)</th>\n",
       "      <td>0.679245</td>\n",
       "      <td>0.580952</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.592275</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.675325</td>\n",
       "      <td>0.702479</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.637168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.882927</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.693182</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.501992</td>\n",
       "      <td>0.820000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows × 465 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "treatment                     K        MS                             K  \\\n",
       "replica                       1         3                   2         2   \n",
       "generation                   39        67        34        27        43   \n",
       "variant_id                                                                \n",
       "(contig000001, 146)    1.000000  0.979592  0.795918  0.945312  1.000000   \n",
       "(contig000001, 227)    1.000000  0.989474  0.858824  0.985849       NaN   \n",
       "(contig000001, 5306)   1.000000  0.651316  1.000000  0.642857  0.565217   \n",
       "(contig000001, 91539)  0.591176  0.516667  0.500000  0.550063  0.507463   \n",
       "(contig000001, 91557)  0.607955  0.531621  0.517073  0.531100  0.507937   \n",
       "...                         ...       ...       ...       ...       ...   \n",
       "(contig000029, 696)    1.000000  0.998117  1.000000  1.000000  1.000000   \n",
       "(contig000032, 8535)   0.994152  0.969027  0.176166  0.997727  1.000000   \n",
       "(contig000038, 58)          NaN  0.863636  0.758621  0.918367  1.000000   \n",
       "(contig000038, 105)         NaN  0.180000  0.842105  0.177419  0.000000   \n",
       "(contig000038, 155)    0.679245  0.580952  0.547619  0.592275  0.985714   \n",
       "\n",
       "treatment                                                  MS            ...  \\\n",
       "replica                                 1                   3         2  ...   \n",
       "generation                   14        38        63         8         4  ...   \n",
       "variant_id                                                               ...   \n",
       "(contig000001, 146)    1.000000  0.725490  0.678571  0.851064  1.000000  ...   \n",
       "(contig000001, 227)    1.000000  0.893204  0.840426  0.885714  1.000000  ...   \n",
       "(contig000001, 5306)   0.958333  1.000000  0.535088  0.581818  1.000000  ...   \n",
       "(contig000001, 91539)  0.522642  0.733607  0.503704  0.548209  0.545098  ...   \n",
       "(contig000001, 91557)  0.543119  0.736842  0.523810  0.548052  0.558226  ...   \n",
       "...                         ...       ...       ...       ...       ...  ...   \n",
       "(contig000029, 696)    1.000000  1.000000  0.992620  1.000000  1.000000  ...   \n",
       "(contig000032, 8535)   0.960000  1.000000  0.986755  0.400000  1.000000  ...   \n",
       "(contig000038, 58)     1.000000  0.515152  0.681818  0.500000  1.000000  ...   \n",
       "(contig000038, 105)    0.178571  0.659091  0.456790  0.629630  0.172414  ...   \n",
       "(contig000038, 155)    0.652174  0.675325  0.702479  0.545455  0.637168  ...   \n",
       "\n",
       "treatment                     K        MS                   K            \\\n",
       "replica                       2         3                   2             \n",
       "generation                   57        59        17        27        46   \n",
       "variant_id                                                                \n",
       "(contig000001, 146)    1.000000  0.533632  1.000000  0.930233  1.000000   \n",
       "(contig000001, 227)    1.000000  0.672840  1.000000  0.937984  1.000000   \n",
       "(contig000001, 5306)   1.000000  1.000000  1.000000  0.523529  0.837696   \n",
       "(contig000001, 91539)  0.558763  0.684380  0.552486  0.516393  0.590840   \n",
       "(contig000001, 91557)  0.558577  0.670455  0.542328  0.523810  0.602056   \n",
       "...                         ...       ...       ...       ...       ...   \n",
       "(contig000029, 696)    0.997881  1.000000  1.000000  1.000000  0.998752   \n",
       "(contig000032, 8535)   1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "(contig000038, 58)     1.000000  0.644628       NaN       NaN  1.000000   \n",
       "(contig000038, 105)    0.142857  0.503205       NaN  0.785714  0.086957   \n",
       "(contig000038, 155)    0.566038  0.882927  0.783784  0.583333  0.693182   \n",
       "\n",
       "treatment                    MS                   K                      \n",
       "replica                       3                   2         3         2  \n",
       "generation                   43        50        36         7        77  \n",
       "variant_id                                                               \n",
       "(contig000001, 146)    0.813953  0.888889  1.000000  1.000000  1.000000  \n",
       "(contig000001, 227)    0.857143  0.979592  1.000000  0.996000  1.000000  \n",
       "(contig000001, 5306)   0.847222  1.000000  1.000000  1.000000  0.854962  \n",
       "(contig000001, 91539)  0.519231  0.847826  0.541237  1.000000  0.507331  \n",
       "(contig000001, 91557)  0.511848  0.866667  0.522843  0.998088  0.512676  \n",
       "...                         ...       ...       ...       ...       ...  \n",
       "(contig000029, 696)    1.000000  1.000000  1.000000  0.998371  1.000000  \n",
       "(contig000032, 8535)   1.000000  0.988889  0.989796  0.998294  1.000000  \n",
       "(contig000038, 58)          NaN       NaN       NaN  1.000000       NaN  \n",
       "(contig000038, 105)    0.695652       NaN       NaN  0.095745       NaN  \n",
       "(contig000038, 155)    0.565217  0.628571  0.827586  0.501992  0.820000  \n",
       "\n",
       "[222 rows x 465 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def merge_contig_and_position(df): \n",
    "    return df.assign(variant_id=df[[\"contig\", \"position\"]].apply(tuple, axis=1))\n",
    "\n",
    "major_allele_freq_df = ( \n",
    "    freq_df.assign(value=freq_df.value.apply(get_freq))\n",
    "    .query(\"value.notna()\")\n",
    "    .assign(replica=lambda x: x['replica'].astype(int))\n",
    "    .drop(\"sample\", axis=1)\n",
    "    .pivot(\n",
    "        columns=[\"treatment\", \"replica\", \"generation\"], \n",
    "        index=[\"contig\", \"position\"], values=\"value\")\n",
    "    .reset_index()\n",
    "    .pipe(merge_contig_and_position)\n",
    "    .set_index('variant_id')\n",
    "    .drop([\"contig\", \"position\"], axis=1) )\n",
    "\n",
    "major_allele_freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "FREQ_WIDE_PKL = \"freq_dataframe_wide_ref1.pkl\"\n",
    "# assert not os.path.exists(FREQ_WIDE_PKL), f\"{FREQ_WIDE_PKL} already exists, not overwriting it.\"\n",
    "\n",
    "pkl.dump(major_allele_freq_df, open(FREQ_WIDE_PKL, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plant_gwas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
